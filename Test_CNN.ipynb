{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9270dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import random\n",
    "from glob import glob\n",
    "import cv2 \n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "\n",
    "import argparse\n",
    "#import torch\n",
    "#import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "#from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc1a873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3807, 128, 128, 3)\n",
      "(3807,)\n",
      "(3045, 128, 128, 3)\n",
      "(381, 128, 128, 3)\n",
      "(381, 128, 128, 3)\n",
      "torch.Size([1, 128, 128]) 0\n",
      "3045\n",
      "381\n",
      "381\n"
     ]
    }
   ],
   "source": [
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, images, labels, transform=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.images[idx].astype(np.uint8)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "# Load the data(images)\n",
    "x_npz = np.load(\"data/x_images_arrays.npz\")\n",
    "X = x_npz[\"arr_0\"]\n",
    "y_npz = np.load(\"data/y_labels_arrays.npz\")\n",
    "Y = y_npz[\"arr_0\"]\n",
    "\n",
    "print(np.array(X).shape)\n",
    "print(np.array(Y).shape)\n",
    "\n",
    "# Separete the data into train, val and test sets\n",
    "# 80% train, 10% val, 10% test\n",
    "x_train, x_temp, y_train, y_temp = train_test_split(X, Y, test_size=0.2,random_state=1, stratify=Y)\n",
    "\n",
    "x_test, x_val, y_test, y_val = train_test_split(x_temp, y_temp, test_size=0.5, random_state=1, stratify=y_temp)\n",
    "\n",
    "print(np.array(x_train).shape)\n",
    "print(np.array(x_val).shape)\n",
    "print(np.array(x_test).shape)\n",
    "# (3045, 128, 128, 3)\n",
    "# (381, 128, 128, 3)\n",
    "# (381, 128, 128, 3)\n",
    "\n",
    "# Transform the data to tensor\n",
    "# Define a transform\n",
    "transform = transforms.Compose([\n",
    "            #transforms.Resize((28, 28)),\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Grayscale(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0,), (1,))])\n",
    "\n",
    "# Apply the transform to the data\n",
    "dataset_train = CustomImageDataset(x_train, y_train, transform=transform)\n",
    "dataset_val = CustomImageDataset(x_val, y_val, transform=transform)\n",
    "dataset_test = CustomImageDataset(x_val, y_val, transform=transform)\n",
    "\n",
    "img, label = dataset_train[0]\n",
    "print(img.shape, label) # [grayscale=1, size=128, size=128] label=0 ('Nothing')\n",
    "print(dataset_train.__len__()) # 3045 images\n",
    "print(dataset_val.__len__()) # 381 images\n",
    "print(dataset_test.__len__()) # 381 images\n",
    "\n",
    "# Load into the DataLoader\n",
    "batch_size = 32\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(dataset_val, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc118c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantidade de imagens por classe no conjunto de treino:\n",
      "Classe 0: 2435 imagens\n",
      "Classe 2: 402 imagens\n",
      "Classe 1: 208 imagens\n",
      "Quantidade de imagens por classe no conjunto de treino:\n",
      "Classe 0: 304 imagens\n",
      "Classe 1: 26 imagens\n",
      "Classe 2: 51 imagens\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class_counts_train = Counter(y_train)\n",
    "print(\"Quantidade de imagens por classe no conjunto de treino:\")\n",
    "for class_id, count in class_counts_train.items():\n",
    "    print(f\"Classe {class_id}: {count} imagens\")\n",
    "\n",
    "class_counts_test = Counter(y_val)\n",
    "print(\"Quantidade de imagens por classe no conjunto de teste:\")\n",
    "for class_id, count in class_counts_test.items():\n",
    "    print(f\"Classe {class_id}: {count} imagens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "373a2336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Architecture\n",
    "entry_channels = 1\n",
    "exit_channels = 16\n",
    "kernel_size = 3\n",
    "stride = 1\n",
    "num_inputs = 128*128\n",
    "num_hidden = 1000\n",
    "num_outputs = 3 # classes\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"mps\") if torch.backends.mps.is_available() else torch.device(\"cpu\")\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(entry_channels, exit_channels, kernel_size, stride, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(exit_channels*num_inputs, num_hidden)\n",
    "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)  # Ativação após conv1\n",
    "        #x = F.max_pool2d(x, 2)  # Reduz dimensões (opcional, ajusta tamanho)\n",
    "        x = torch.flatten(x, 1)  # Achatamento\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)  # Ativação após fc1\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)  # Saída com softmax\n",
    "        return output\n",
    "    \n",
    "model = Net().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dbbef6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from ./models/cnn1.pth\n"
     ]
    }
   ],
   "source": [
    "PATH = './models/cnn1.pth'\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.eval()\n",
    "print(f\"Model loaded from {PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e7e8fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total correctly classified test set images: 304/381\n",
      "Test Set Accuracy: 79.79%\n",
      "Precision: 0.27\n",
      "Recall: 0.33\n",
      "F1-score: 0.30\n",
      "\n",
      "Matriz de Confusão:\n",
      "[[304   0   0]\n",
      " [ 26   0   0]\n",
      " [ 51   0   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\giueg\\.virtualenvs\\TCC_25-OGy0qkdu\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Função para calcular métricas\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_true, y_pred, average='macro') # average = 'weighted' | 'micro' | 'macro'\n",
    "    return precision, recall, f1\n",
    "\n",
    "# Listas para armazenar previsões e rótulos verdadeiros\n",
    "all_preds = []\n",
    "all_targets = []\n",
    "\n",
    "# Avaliação do modelo\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    for data, targets in test_loader:\n",
    "        data = data.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        test_data = model(data)\n",
    "\n",
    "        # Previsões\n",
    "        _, predicted = test_data.max(1)\n",
    "\n",
    "        # Acumular acurácia\n",
    "        total += targets.size(0)\n",
    "        correct += (predicted == targets).sum().item()\n",
    "\n",
    "        # Armazenar previsões e rótulos para F1 e matriz de confusão\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "# Calcular acurácia\n",
    "print(f\"Total correctly classified test set images: {correct}/{total}\")\n",
    "print(f\"Test Set Accuracy: {100 * correct / total:.2f}%\")\n",
    "\n",
    "# Calcular precisão, recall e F1-score\n",
    "precision, recall, f1 = calculate_metrics(all_targets, all_preds) \n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-score: {f1:.2f}\")\n",
    "\n",
    "# Calcular e exibir a matriz de confusão\n",
    "conf_matrix = confusion_matrix(all_targets, all_preds)\n",
    "print(\"\\nMatriz de Confusão:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TCC_25-OGy0qkdu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
